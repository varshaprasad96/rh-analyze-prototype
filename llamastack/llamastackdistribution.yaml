apiVersion: llamastack.io/v1alpha1
kind: LlamaStackDistribution
metadata:
  name: llama-stack
  namespace: NAMESPACE_PLACEHOLDER
  annotations:
    openshift.io/display-name: llama-stack
  labels:
    opendatahub.io/dashboard: "true"
spec:
  replicas: 1
  server:
    containerSpec:
      command:
      - /bin/sh
      - -c
      - llama stack run /etc/llama-stack/run.yaml
      env:
      - name: VLLM_TLS_VERIFY
        value: "false"
      - name: MILVUS_DB_PATH
        value: ~/.llama/milvus.db
      - name: FMS_ORCHESTRATOR_URL
        value: http://localhost
      - name: VLLM_MAX_TOKENS
        value: "4096"
      - name: VLLM_API_TOKEN_1
        value: fake
      - name: LLAMA_STACK_CONFIG_DIR
        value: /opt/app-root/src/.llama/distributions/rh/
      # OpenTelemetry configuration for MLflow tracing
      - name: OTEL_EXPORTER_OTLP_ENDPOINT
        value: "http://otel-collector.NAMESPACE_PLACEHOLDER.svc.cluster.local:4318"
      - name: OTEL_EXPORTER_OTLP_PROTOCOL
        value: "http/protobuf"
      - name: OTEL_SERVICE_NAME
        value: "llama-stack"
      name: llama-stack
      port: 8321
      resources:
        limits:
          cpu: "2"
          memory: 12Gi
        requests:
          cpu: 250m
          memory: 500Mi
    distribution:
      name: rh-dev
    userConfig:
      configMapName: llama-stack-config
